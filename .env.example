# Ollama Cloud Configuration
# Set to 1 to use Ollama Cloud; 0 for local offload daemon
USE_DIRECT_CLOUD=1

# Ollama API Key (required when USE_DIRECT_CLOUD=1)
OLLAMA_API_KEY=

# Model Configuration
PLANNER_MODEL=deepseek-v3.1:671b
ACTOR_MODEL=qwen3-coder:480b

# Frontend E2E/Dev Flags
# Vite reads these at build time for the UI.
VITE_MOCK_MODE=true
# Optional: enable orchestrator E2E (requires real backend + API key)
# E2E_ORCHESTRATOR=1

# (Deprecated) WebSocket Configuration — transport now uses Tauri events
# UICP_WS_URL=ws://localhost:7700

# Ollama Endpoints
OLLAMA_CLOUD_HOST=https://ollama.com
OLLAMA_LOCAL_BASE=http://127.0.0.1:11434/v1

